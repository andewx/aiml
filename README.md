# aiml
Notebooks, Materials, Notes &amp; Projects for CSC532

# course syllabus 

------------------

# textbooks and materials

## core

- [Machine Learning with R - Third Edition - Brett Lantz](https://www.oreilly.com/library/view/machine-learning-with/9781788295864/)
- [An Introduction to Statistical Learning with Application in R - 2nd Edition - Garteh James, et al] (https://hastie.su.domains/ISLR2/ISLRv2_website.pdf)

## supplemental

- [Practical Statistics for Data Scientists, 2nd Edition - Peter Bruce, et al.](https://learning.oreilly.com/library/view/practical-statistics-for/9781492072935/)
- [The Elements of Statistical Learning, Mining, Inference, and Prediction, 2nd Edition - Trevor Hastie, et al.](https://web.stanford.edu/~hastie/ElemStatLearn/)
- [Pattern Recognition and Machine Learning - Christopher Bishop](http://research.microsoft.com/en-us/um/people/cmbishop/prml/)
- [Machine Learning - Tom Mitchell](http://www.cs.cmu.edu/~tom/mlbook.html)
- [Probablistic Machine learning: An Introduction - Kevin Murphy](https://probml.github.io/pml-book/book1.html)
- [Deep Learning with R - Franic Chollet, J.J. Allaire] - (https://www.manning.com/books/deep-learning-with-r)


## modules

| Week/Module | Tasks |
| ----------- | ----------- |
| Week/Module | Tasks |
| 1. A brief review of statistics | Week 1 quiz, discussion 1 | 

| 1. A Brief Review of Statistics | Week 1 quiz, Discussion1  |
| 2. Introduction to Machine Learning,  |  A brief Introduction to R  Week 2 quiz, discussion2 |  
| 3. Exploring and understanding data |  Week 3 quiz, assignment 1  | 
| 4. Lazy learning: Classification using nearest neighbors |  Week 4 quiz | 
| 5 Probabilistic learning: Classification using naïve Bayes | Week 5 quiz, assignment 2  | 
| 6. Divide and conquer: Classification using decision trees and rules| Week 6 quiz | 
| 7. Forecasting numeric data with Regression Models: 
• Linear Regression 
•  Regression Trees 
• Variable selection using Stepwise Regression 
 | Week 7 quiz, assignment 3 | 
 
| 8 & 9 : Black box Models I: Intro to neural networks  
• Multi-layer perceptron, gradient descent and 
backpropagation algorithm  
• building a MultiLayer Perceptron with Keras and 
Tensorflow 
•  Neural Networks for classification( softmax activation 
function and cross-entropy loss) 
• Hyper-parameter Tuning 
|  
Weeks 8&9 quiz , discussion 
3, assignment 3 | 
 
| 10 : Black box Models II: Intro to support vector machines | Week 10 quiz | 
| 11 & 12:   
 
Evaluating model performance 
• Kappa Statistics, Precision and Recall, F-measure, ROC 
curves 
• Resampling (bootstrap, cross validation) 
Improving Model Performance 
• Hyper-parameter tuning 
• Battling overfitting with Regularization 
o Lasso, Ridge, dropout for neural networks 
• Model Ensemble 
o Bagging, Random Forest 
o Boosting (Ada Boost, Gradient Boosted Trees) | 
Weeks 11&12 quiz , 
assignment 5, Discussion 4. | 
| 13 & 14  
 Unsupervised Learning  
• Dimensionality Reduction 
o PCA 
o Auto-encoder 
o Sparse Data Embeddings 
• Clustering 
o Kmeans 
 Week 13&14 quiz | 
| 15  No Lecture, Work on Final Project | Final Project |

